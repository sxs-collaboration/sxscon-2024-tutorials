{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with SpECTRE data\n",
    "\n",
    "In this tutorial we will look at the output data that SpECTRE simulations\n",
    "produce and learn how to work with them in Python.\n",
    "\n",
    "> Note that many of the functions we use here are also available on the command\n",
    "> line, so you don't have to jump into Python to do quick plots. Explore what's\n",
    "> available on the command line with `spectre --help`. We will point to specific\n",
    "> subcommands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rich\n",
    "import rich.columns\n",
    "from pathlib import Path\n",
    "from spectre.Visualization.Plot import DEFAULT_MPL_STYLESHEET\n",
    "\n",
    "plt.style.use(DEFAULT_MPL_STYLESHEET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some sample data from a complete BBH inspiral that we will be working\n",
    "with in this tutorial (though you can also use your own data of course):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_dir = Path(\"/oscar/data/icerm/knelli/workshop_materials/01_monday/bbh_inspiral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with reduction data\n",
    "\n",
    "Reduction data is collected from the simulation as a whole and written to a\n",
    "single H5 file with multiple subfiles. For example, the L2 norm over all grid\n",
    "points of a quantity would be written as reduction data. Here's an overview of\n",
    "the data in the BBH reductions file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductions_file = segment_dir / \"BbhReductions.h5\"\n",
    "with h5py.File(reductions_file) as open_reductions_file:\n",
    "    rich.print(rich.columns.Columns(open_reductions_file.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reductions data is written in simple matrix form with a legend, so a\n",
    "`pandas.DataFrame` is the great representation of this data. The [`to_dataframe`](https://spectre-code.org/py/_autosummary/spectre.Visualization.ReadH5.html#spectre.Visualization.ReadH5.to_dataframe)\n",
    "function simply reads the legend and returns a DataFrame with named columns:\n",
    "\n",
    "> Documentation of the `spectre` Python modules is available here: https://spectre-code.org/py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectre.Visualization.ReadH5 import to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(reductions_file) as open_reductions_file:\n",
    "    subfile = open_reductions_file[\"Norms.dat\"]\n",
    "    legend = subfile.attrs[\"Legend\"]\n",
    "    norms = pd.DataFrame(subfile, columns=legend)\n",
    "    # This function does the above in one line:\n",
    "    norms = to_dataframe(open_reductions_file[\"Norms.dat\"])\n",
    "norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Constraint norms\n",
    "\n",
    "The data we read above can easily be plotted. It shows the evolution of the\n",
    "generalized-harmonic constraints throughout the inspiral.\n",
    "\n",
    "> **On the command line:** Try `spectre plot dat --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_labels = [label for label in norms.columns if \"Constraint\" in label]\n",
    "norms.plot(x=\"Time\", y=norm_labels, logy=True, ylim=(1e-8, None));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Horizon quantities\n",
    "\n",
    "Here's the evolution of the primary black hole's mass throughout the inspiral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(reductions_file) as open_reductions_file:\n",
    "    AhA = to_dataframe(open_reductions_file[\"ObservationAhA.dat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AhA.plot(x=\"Time\", y=\"ChristodoulouMass\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Trajectories\n",
    "\n",
    "Here's the trajectory of the two black holes:\n",
    "\n",
    "> **On the command line:** Try `spectre plot trajectories --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(reductions_file) as open_reductions_file:\n",
    "    AhA_coords = to_dataframe(\n",
    "        open_reductions_file[\"ApparentHorizons/ControlSystemAhA_Centers.dat\"]\n",
    "    )\n",
    "    AhB_coords = to_dataframe(\n",
    "        open_reductions_file[\"ApparentHorizons/ControlSystemAhB_Centers.dat\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(AhA_coords[\"InertialCenter_x\"], AhA_coords[\"InertialCenter_y\"])\n",
    "plt.plot(AhB_coords[\"InertialCenter_x\"], AhB_coords[\"InertialCenter_y\"])\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Time steps\n",
    "\n",
    "To give you a taste of our asynchronous simulations in SpECTRE, let's look at\n",
    "the time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(reductions_file) as open_reductions_file:\n",
    "    time_steps = to_dataframe(open_reductions_file[\"TimeSteps.dat\"])\n",
    "time_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the minimum and maximum time step throughout the inspiral.\n",
    "We are using local time stepping, so some elements take smaller time steps than\n",
    "others. The time step data is recorded at \"slabs\", which are time step\n",
    "boundaries that all elements share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps.plot(x=\"Time\", y=[\"Minimum time step\", \"Maximum time step\"], logy=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walltime_diff = time_steps[\"Maximum Walltime\"] - time_steps[\"Minimum Walltime\"]\n",
    "plt.hist(np.log10(walltime_diff), bins=100)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"$\\log_{10}(T_\\mathrm{max} - T_\\mathrm{min})$ in seconds\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, apparently, for most slabs in this run the first and last element to\n",
    "complete the slab did so within 10 seconds of each other, but for some slabs\n",
    "this spread was almost 100 seconds! Note that this doesn't mean the slab took\n",
    "this long to complete, just that the different elements did so asynchronously at\n",
    "different walltimes while their respective compute core was busy doing other\n",
    "work.\n",
    "\n",
    "> To learn more about our asynchronous task-based parallelism you will have to\n",
    "> wait until Thursday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with 3D volume data\n",
    "\n",
    "Volume data is 3D tensor data on all grid points of the computational domain.\n",
    "This can be a lot of data (40GB for the sample inspiral data that we are looking\n",
    "at here, which is at relatively low resolution), so we only write it sparingly,\n",
    "and often only in single-precision floating point format. However, it can be\n",
    "very valuable to understand issues with your simulations, and of course enables\n",
    "you to create full 3D visualizations of your simulations. Also, volume data can\n",
    "be used to start and restart simulations, so e.g. initial data is written in\n",
    "this form.\n",
    "\n",
    "SpECTRE simulations write one H5 volume data file per node, which is why you\n",
    "will find multiple volume data files labeled with consecutive integers in your\n",
    "output directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export BBH_DATA=/oscar/data/icerm/knelli/workshop_materials/01_monday/bbh_inspiral\n",
    "\n",
    "ls $BBH_DATA/BbhVolume*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will look at volume data interactively in ParaView, we will make quick\n",
    "3D renderings using the CLI, and we will load the data in Python to make 2D\n",
    "plots. On Friday we will look closer at initial data and how to interpolate\n",
    "volume data to different grids (and possibly different codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive 3D visualization with ParaView\n",
    "\n",
    "To look at our simulation interactively in ParaView, we first have to generate\n",
    "an XDMF file that references the data in the H5 volume data files so that\n",
    "ParaView understands them. This is easiest done on the command line (though it's\n",
    "also available in Python). We generate XDMF files for the volume data as well as\n",
    "the horizon surfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export BBH_DATA=/oscar/data/icerm/knelli/workshop_materials/01_monday/bbh_inspiral\n",
    "\n",
    "spectre generate-xdmf $BBH_DATA/BbhVolume*.h5 -d VolumeData -o runs/Bbh.xmf\n",
    "spectre generate-xdmf $BBH_DATA/BbhSurfaces.h5 -d ObservationAhA -o runs/AhA.xmf\n",
    "spectre generate-xdmf $BBH_DATA/BbhSurfaces.h5 -d ObservationAhB -o runs/AhB.xmf\n",
    "spectre generate-xdmf $BBH_DATA/BbhSurfaces.h5 -d ObservationAhC -o runs/AhC.xmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch over to ParaView\n",
    "\n",
    "You could download all the data to your local machine, but this takes a long\n",
    "time and is often impossible because the volume data files are just too big.\n",
    "Instead, we can establish a remote ParaView connection to the cluster, so the\n",
    "data can remain on the cluster and we only control the visualization from our\n",
    "local machine. To do this, follow the instructions on the [tutorial repo\n",
    "README](https://github.com/sxs-collaboration/sxscon-2024-tutorials#6-connection-paraview-to-oscar)\n",
    "to open a remote ParaView connection.\n",
    "\n",
    "Once connected, open the `Bbh.xmf` file and the horizon files in ParaView.\n",
    "Select \"XDMF Reader\" when prompted for a reader to open the file. Now you can\n",
    "play around with the data in 3D to your heart's content. You can try the\n",
    "following:\n",
    "\n",
    "- Create a slice or clip through the domain to see its interior.\n",
    "- Switch to \"Surface with Edges\" to see the grid lines.\n",
    "- Look at different quantities, such as the lapse or shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick 3D renderings with the CLI\n",
    "\n",
    "On the command line you can do quick renderings of your volume data with the\n",
    "commands in the `spectre render-3d` subcommand. For example, try this to\n",
    "visualize the domain structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "spectre render-3d domain runs/Bbh.xmf -o runs/domain.png --zoom 20 --slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BBH domain](images/domain.png)\n",
    "\n",
    "The thicker black lines are the boundaries of what we call blocks. Blocks are\n",
    "the fundamental \"building blocks\" (pun definitely intended) of our computational\n",
    "domain. You cannot coarsen a block. The thinner grey lines are the boundaries of\n",
    "what we call elements. We split blocks in 2 in each logical direction for extra\n",
    "refinement and the result are a bunch of elements. You'll hear more about how we\n",
    "do refinement tomorrow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot slices in Python\n",
    "\n",
    "You can also load the volume data in Python and interpolate to any set of\n",
    "points. This allows you to do slice plots, e.g. for papers.\n",
    "\n",
    "> **On the command line:** Try `spectre plot {along-line|slice} --help` to do\n",
    "> quick 1D or 2D plots of your volume data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from spectre.IO.Exporter import interpolate_to_points\n",
    "from spectre.Visualization.OpenVolfiles import open_volfiles\n",
    "from spectre.Visualization.ReadH5 import list_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we collect all volume data files and the observations that they contain.\n",
    "Each observation is identified by an _observation ID_, which is essentially a\n",
    "hash of its time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volfiles = glob.glob(str(segment_dir / \"BbhVolume*.h5\"))\n",
    "obs_ids, obs_times = list_observations(\n",
    "    open_volfiles(volfiles, subfile_name=\"VolumeData\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can interpolate the volume data to a rectangular grid for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of a rectangular grid in the xy plane\n",
    "x, y = np.meshgrid(np.linspace(-15, 15, 300), np.linspace(-15, 15, 300))\n",
    "z = np.zeros(x.shape)\n",
    "\n",
    "# interpolate_to_points returns an array whose length corresponds to the number\n",
    "# of components of the tensors in the 'tensor_components' argument. Then for\n",
    "# each component, there is a 1D array of data corresponding to the\n",
    "# 'target_points'\n",
    "lapse = np.array(\n",
    "    interpolate_to_points(\n",
    "        volfiles,\n",
    "        subfile_name=\"VolumeData\",\n",
    "        observation_id=obs_ids[0],\n",
    "        tensor_components=[\"Lapse\"],\n",
    "        target_points=[x.flatten(), y.flatten(), z.flatten()],\n",
    "    )[0]\n",
    ").reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lapse\n",
    "plt.contourf(x, y, np.log(1 - lapse))\n",
    "\n",
    "# Plot circles for black holes (note that excisions are hardly ever circles)\n",
    "ax = plt.gca()\n",
    "for bh_pos in [-7.683, 7.683]:\n",
    "    ax.add_patch(\n",
    "        plt.Circle(xy=(bh_pos, 0), radius=0.791616184028402, color=\"black\", fill=True)\n",
    "    )\n",
    "\n",
    "# Make plot square\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual elements\n",
    "\n",
    "You can also iterate over elements in your volume data to plot things like\n",
    "element boundaries, collocation points, etc. Use `iter_elements`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectre.IO.H5.IterElements import iter_elements\n",
    "\n",
    "# Create a 3D plot\n",
    "ax = plt.gcf().add_subplot(111, projection=\"3d\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Iterate over elements\n",
    "for element in iter_elements(\n",
    "    open_volfiles(volfiles, subfile_name=\"VolumeData\"),\n",
    "    obs_ids=obs_ids[0],\n",
    "    element_patterns=[\"B3,(L1I0,L1I0,*)\"],  # Only plot radial elements in block 3\n",
    "):\n",
    "    # Draw outline of the element by mapping the edges of the logical cube to\n",
    "    # inertial coordinates using the element map\n",
    "    for d in range(3):\n",
    "        for edge in range(4):\n",
    "            line = np.zeros((3, 100))\n",
    "            line[d, :] = np.linspace(-1, 1, 100)\n",
    "            line[(d + 1) % 3, :] = 2 * (edge % 2) - 1\n",
    "            line[(d + 2) % 3, :] = 2 * (edge // 2) - 1\n",
    "            x, y, z = element.map(line, element.time, element.functions_of_time)\n",
    "            ax.plot(x, y, z, color=\"black\")\n",
    "\n",
    "# Make plot square\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power monitors\n",
    "\n",
    "Power monitors are a powerful (ðŸ˜Ž) tool to analyze how well your domain resolves\n",
    "your data. They are essentially the spectral coefficients of your data in each\n",
    "element of the domain, marginalized over each logical dimension.\n",
    "\n",
    "> You will learn more about power monitors tomorrow!\n",
    "\n",
    "Power monitors are very easy to plot from the command line, so give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export BBH_DATA=/oscar/data/icerm/knelli/workshop_materials/01_monday/bbh_inspiral\n",
    "\n",
    "spectre plot power-monitors $BBH_DATA/BbhVolume*.h5 -d VolumeData -y Lapse \\\n",
    "  -b ObjectAShell -b ObjectACube -b Envelope -b OuterShell \\\n",
    "  --time 1000 -o runs/power_monitors.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![power monitors](images/power_monitors.png)\n",
    "\n",
    "Here you see the power monitors of the lapse function at time 1000M in the\n",
    "sample BBH data. Each curve corresponds to an element, and each panel shows a\n",
    "different region of the domain (see the grid visualization above). Spectral\n",
    "coefficients in the radial direction are red, and in the two angular directions\n",
    "are blue and green.\n",
    "\n",
    "This plot seems to tell us that at this time in the evolution, the accuracy of\n",
    "the simulation is limited by the resolution in the cubes surrounding the black\n",
    "holes. We could increase the polynomial order of the spectral expansion in these\n",
    "elements to increase accuracy, or reduce the polynomial order in the inner\n",
    "shell, envelope, and outer shell to save computational cost. This would be the\n",
    "job of our adaptive mesh-refinement (AMR) algorithm, which you will also learn\n",
    "more about tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming volume data\n",
    "\n",
    "Often you want to post-process volume data to compute derived quantities from\n",
    "the ones the simulation has written out. You can sometime do this within tools\n",
    "like ParaView (e.g. using ParaView's \"Calculator\" filter) if the computation is\n",
    "simple enough and pointwise (i.e., needs no derivatives or other mesh\n",
    "information). If you can't get what you need in ParaView, you can use `spectre\n",
    "transform-vol`. It takes any Python function (a \"kernel\"), runs it over your\n",
    "volume data, and writes the result back into the files.\n",
    "\n",
    "To try this, copy one of the sample data files first:\n",
    "\n",
    "```sh\n",
    "cp $BBH_DATA/BbhVolume0.h5 ./runs\n",
    "```\n",
    "\n",
    "Now let's compute an estimate of the relative truncation error in each element,\n",
    "which uses the power monitors that we looked at above:\n",
    "\n",
    "```sh\n",
    "spectre transform-vol BbhVolume0.h5 -d VolumeData \\\n",
    "    -k spectre.NumericalAlgorithms.LinearOperators.relative_truncation_error\n",
    "```\n",
    "\n",
    "You will be prompted to select a dataset name for the `tensor_component`\n",
    "argument of the `relative_truncation_error` function (type in \"Lapse\") and for\n",
    "the output data set name (hit enter to select the default\n",
    "\"RelativeTruncationError\"). The result of the computation will be written back\n",
    "into the H5 files. If you now regenerate an XDMF file for the volume data you\n",
    "will be able to see the output of this function in ParaView.\n",
    "\n",
    "You can also write your own kernels in Python. Create a Python file, e.g.\n",
    "`kernel.py`, and write a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file runs/kernel.py\n",
    "from spectre.DataStructures.Tensor import Scalar, DataVector\n",
    "\n",
    "def lapse_squared(lapse: Scalar[DataVector]) -> Scalar[DataVector]:\n",
    "    return np.array(lapse)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inside the `runs/visualization` directory you can run this kernel over your volume data like this:\n",
    "\n",
    "```sh\n",
    "spectre transform-vol runs/BbhVolume0.h5 -d VolumeData -e runs/kernel.py -k lapse_squared\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
